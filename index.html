<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html data-lt-installed="true">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <link rel="stylesheet" href="index_files/main.css" type="text/css">
    <title>Yunlu Chen</title>
  </head>
  <body data-new-gr-c-s-check-loaded="14.1047.0"
    data-gr-ext-installed="">
    <div id="layout-content">
      <div id="toptitle">
        <h1>Yunlu Chen</h1>
      </div>
      Ph.D. candidate, University of Amsterdam
      <p>3D deep learning<br>
        <a
          href="https://scholar.google.nl/citations?user=BtLaYmUAAAAJ&amp;hl=en"
          target="_blank">Google Scholar</a></p>
      <p>Contact: ychen9201 AT gmail.com </p>
      <h2>Bio</h2>
      <p>I am a final-year PhD student at University of Amsterdam
        (UvA), working on 3D deep learning.<br>
      </p>
      <p>I am grateful to be supervised by <a moz-do-not-send="true"
          href="https://www.egavves.com/">Efstratios Gavves</a>, <a
          moz-do-not-send="true" href="https://www.mensink.nu/">Thomas
          Mensink</a> and <a moz-do-not-send="true"
          href="https://staff.fnwi.uva.nl/a.w.m.smeulders/cv.html">Arnold














          Smeulders</a> at UvA. I also received guidance from some great
        external senior researchers: <a moz-do-not-send="true"
          href="https://basurafernando.github.io/">Basura Fernando</a>
        (A*STAR, Singapore), <a moz-do-not-send="true"
          href="https://homepages.inf.ed.ac.uk/hbilen/">Hakan Bilen</a>
        (University of Edinburgh), and <a moz-do-not-send="true"
href="https://www.niessnerlab.org/members/matthias_niessner/profile.html">Matthias













          Nießner</a> (Technical University of Munich) that collaborated
        in my research projects.<br>
      </p>
      <p>Prior to my Ph.D., I obtained my B.Sc. in Physics from Fudan
        University, China, and my M.Sc. (cum laude) in Artificial
        Intelligence from Utrecht University, the Netherlands.<br>
      </p>
      <h2>Research</h2>
      <p>My research lies at the intersection of deep learning and 3D
        computer vision. I build deep learning models for different 3D
        modalities. Some prior projects include monocular depth
        estimation, RGB-D semantic segmentation, and augmentation for
        point cloud recognition.</p>
      <p>My recent projects focus on the fascinating field of neural
        implicit 3D representations, with the sense of continuity in the
        3D Euclidean space that we live in. Some interesting highlights
        of my research in this direction are the observation of the
        emerging layer hierarchy and correspondence in the latent-coded
        implicit functions, as well as the improved generalization to
        unseen similarity transformations by leveraging the graph
        embedding and the inductive prior of equivariance.</p>
      <h2>Papers<br>
      </h2>
      <table class="papers" cellspacing="0" cellpadding="20" border="0"
        align="center" width="100%">
        <!-- begin entry --> <tbody>
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry -->
          <!-- begin entry --> <tr>
            <td class="thumbs">
              <p><img src="index_files/equivariant_implicit.gif" alt=""
                  moz-do-not-send="true" width="400" height="240"></p>
            </td>
            <td class="detail">
              <p><b id="papertitle">3D Equivariant Graph Implicit Functions<br>
                </b><u>Yunlu Chen</u>, Basura Fernando, Hakan Bilen,
                Matthias Nießner, Efstratios Gavves</p>
              <p><i>ECCV 2022</i></p>
              <p>[<a moz-do-not-send="true"
                  href="https://staff.fnwi.uva.nl/y.chen3/3DEGIF/paper.pdf">paper</a>]
                [<a moz-do-not-send="true"
                  href="https://yunlu-chen.github.io/EquiGraphImplicit/">Project</a>]
                [<a moz-do-not-send="true"
                  href="https://www.youtube.com/watch?v=MrKrnHhk8IA">video</a>]
                <br>
              </p>
              <p>We propose a novel family of graph-based 3D implicit representations. The non-Euclidean graph embeddings in multiple-scales enable modeling of high-fidelity 3D geometric details and facilitate inherent robustness against geometric transformations. We further incorporate equivariant graph layers for guaranteed generalization to unseen similarity transformations, including rotation, translation, and scaling.
              </p>
            </td>
          </tr>
          <tr>
            <td class="thumbs" style="text-align:center">
              <p><img src="index_files/neural_feature_matching.png"
                  alt="" moz-do-not-send="true" width="400" height="200"></p>
            </td>
            <td class="detail">
              <p><b id="papertitle">Neural Feature Matching in Implicit
                  3D Representations</b><br>
                <u>Yunlu Chen</u>, Basura Fernando, Hakan Bilen, Thomas
                Mensink, Efstratios Gavves</p>
              <p> <i>ICML 2021<br>
                  <br>
                </i>[<a moz-do-not-send="true"
                  href="http://proceedings.mlr.press/v139/chen21f/chen21f.pdf">paper</a>]
                [<a moz-do-not-send="true"
                  href="http://proceedings.mlr.press/v139/chen21f/chen21f-supp.pdf">supp</a>]</p>
              <p><! -- We analyse and understand latent-coded implicit functions by tracking local point trajectories alongside latent space interpolation guided by the feature gradients, from which we observe the hierarchy in the implicit function layers, such that the early layers focus on the coarse outline of the shape, and the deeper layers refine the finer details. In addition, we apply our method to implicit correspondence topology-preserving deformation, and the model trained for shape reconstruction handles inconsistency of semantic part compositions (e.g. chairs with and without armrests), indicating that implicit representations learn semantic concepts without supervision. -- > 
                We observe the emerging structure in implicit representation model layers: early layers reconstruct the coarse shape outline, and deeper layers refine finer details. We additionally show that hidden features in implicit representations learns high-level semantic concepts without supervision, which further allows applications for point matching and deformation between shapes with different semantic components and topology.  </p>
            </td>
          </tr>
          <!-- begin entry --> <tr>
            <td class="thumbs" style="text-align:center">
              <p><img src="index_files/unsharp.png" alt=""
                  moz-do-not-send="true" width="368" height="308"></p>
            </td>
            <td class="detail">
              <p><b id="papertitle">Unsharp Mask Guided Filtering</b><br>
                Zenglin Shi, <u>Yunlu Chen</u>, Efstratios Gavves,
                Pascal Mettes, Cees G.M. Snoek</p>
              <p> <i>TIP 2021<br>
                </i></p>
              <p>[<a moz-do-not-send="true"
                  href="https://arxiv.org/pdf/2106.01428">paper</a>] [<a
                  moz-do-not-send="true"
                  href="https://github.com/shizenglin/Unsharp-Mask-Guided-Filtering">code</a>]<br>
              </p>
              <p>We propose a guided image filtering network that predicts high-frequency residuals from the low-pass filtered input signals, resulting in state-of-the-art results across filtering tasks like upsampling, denoising, and cross-modality filtering.</p>
            </td>
          </tr>
          <!-- begin entry --> <tr>
            <td class="thumbs">
              <p><img src="index_files/pointmixup.gif" alt=""
                  moz-do-not-send="true" width="278" height="350"></p>
            </td>
            <td class="detail">
              <p><b id="papertitle">PointMixup: Augmentation for Point
                  Cloud</b> <br>
                <u>Yunlu Chen</u>*, Vincent Tao Hu*, Efstratios Gavves,
                Thomas Mensink, Pascal Mettes, Pengwan Yang, Cees G.M.
                Snoek (<i>*: equal contribution</i>)</p>
              <p> <i>ECCV 2020 <b><font color="#3333ff"><font
                        color="#000000">(spotlight)</font></font></b></i><i><br>
                  <br>
                </i>[<a moz-do-not-send="true"
href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480341.pdf">paper</a>]
                [<a moz-do-not-send="true"
href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480341-supp.pdf">supp</a>]
                [<a moz-do-not-send="true"
                  href="https://github.com/yunlu-chen/PointMixup">code</a>]</p>
              <p>We developed PointMixup, a novel augmentation and regularization for point clouds. We analyse the mathematical properties of the shortest-path interpolation wrt Earth Mover's Distance, which explains the  effectiveness of the proposed method.</p>
            </td>
          </tr>
          <tr>
            <td class="thumbs">
              <p><img src="index_files/3dnconv.png" alt=""
                  moz-do-not-send="true" width="400" height="263"></p>
            </td>
            <td class="detail">
              <p><b id="papertitle">3D Neighborhood Convolution:
                  Learning Depth-Aware Features for RGB-D and RGB
                  Semantic Segmentation</b> <br>
                <u>Yunlu Chen</u>, Thomas Mensink, Efstratios Gavves</p>
              <p> <i>3DV 2019<br>
                  <br>
                </i>[<a moz-do-not-send="true"
                  href="https://arxiv.org/pdf/1910.01460">paper</a>]<br>
              </p>
              <p>We incorporate depth channel information into 2D network without using a separate stream. Depth information is used to adjust the receptive field of the 2D convolution kernel to be similar to a local 3D neighbourhood.</p>
            </td>
          </tr>
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
          <!-- begin entry -->
          <!-- end entry -->
        </tbody>
      </table>
      <br>
    </div>
    <grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration>
  </body>
</html>
